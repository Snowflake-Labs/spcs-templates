spec:
  container:
  - name: scheduler
    image: /airflow_db/airflow_schema/airflow_repository/airflow:2.7.3
    secrets:
      - snowflakeSecret: airflow_db.airflow_schema.airflow_fernet_key
        secretKeyRef: password
        envVarName: AIRFLOW__CORE__FERNET_KEY
      - snowflakeSecret: airflow_db.airflow_schema.airflow_redis_pwd
        secretKeyRef: password
        envVarName: REDIS_PASSWORD
      - snowflakeSecret: airflow_db.airflow_schema.airflow_postgres_pwd
        secretKeyRef: password
        envVarName: POSTGRES_PASSWORD
    env:
      AIRFLOW_CORE_PARALLELISM: 120
      AIRFLOW__CELERY__BROKER_URL: redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}/${REDIS_DBNUM}
      AIRFLOW__CELERY__FLOWER_PORT: 5555
      AIRFLOW__CELERY__FLOWER_URL_PREFIX: 
      AIRFLOW__CELERY__RESULT_BACKEND_CMD: bash -c 'eval "$DATABASE_CELERY_CMD"'
      AIRFLOW__CELERY__WORKER_AUTOSCALE: 16,8
      AIRFLOW__CELERY__WORKER_CONCURRENCY: 16
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__HOSTNAME_CALLABLE: infra.common.custom_hostname_callable.custom_hostname_callable
      AIRFLOW__CORE__LOAD_EXAMPLES: False
      AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG: 32
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql://$POSTGRES_USER:$POSTGRES_PASSWORD@${DATABASE_HOST}:${DATABASE_PORT}/postgres
      AIRFLOW__LOGGING__LOGGING_LEVEL: INFO
      AIRFLOW__LOGGING__WORKER_LOG_SERVER_PORT: 8793
      AIRFLOW__WEBSERVER__AUTHENTICATE: False
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: True
      AIRFLOW__WEBSERVER__RBAC: False
      AIRFLOW__WEBSERVER__SECRET_KEY: fullsvc
      DATABASE_CELERY_CMD: echo -n "db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${DATABASE_HOST}:${DATABASE_PORT}/postgres"
      DATABASE_HOST: postgres-service.airflow-schema.airflow-db.snowflakecomputing.internal
      DATABASE_PORT: 5432
      POSTGRES_USER: postgres
      REDIS_DBNUM: 0
      REDIS_HOST: redis-service.airflow-schema.airflow-db.snowflakecomputing.internal
      REDIS_PORT: 6379
      USE_HOSTNAME: No
      WORKER_NAME: airflow-worker.airflow-schema.airflow-db.snowflakecomputing.internal
      WORKER_TYPE: ip
    command:
    - bash
    - -c
    - "airflow db init && airflow scheduler"
    volumeMounts:
    - name: dags
      mountPath: /opt/airflow/dags
    - name: airflow-logs
      mountPath: /opt/airflow/logs
  - name: webserver
    image: /airflow_db/airflow_schema/airflow_repository/airflow:2.7.3
    secrets:
      - snowflakeSecret: airflow_db.airflow_schema.airflow_fernet_key
        secretKeyRef: password
        envVarName: AIRFLOW__CORE__FERNET_KEY
      - snowflakeSecret: airflow_db.airflow_schema.airflow_redis_pwd
        secretKeyRef: password
        envVarName: REDIS_PASSWORD
      - snowflakeSecret: airflow_db.airflow_schema.airflow_postgres_pwd
        secretKeyRef: password
        envVarName: POSTGRES_PASSWORD
    env:
      AIRFLOW_CORE_PARALLELISM: 120
      AIRFLOW__CELERY__BROKER_URL: redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}/${REDIS_DBNUM}
      AIRFLOW__CELERY__FLOWER_PORT: 5555
      AIRFLOW__CELERY__FLOWER_URL_PREFIX: 
      AIRFLOW__CELERY__RESULT_BACKEND_CMD: bash -c 'eval "$DATABASE_CELERY_CMD"'
      AIRFLOW__CELERY__WORKER_AUTOSCALE: 16,8
      AIRFLOW__CELERY__WORKER_CONCURRENCY: 16
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__HOSTNAME_CALLABLE: infra.common.custom_hostname_callable.custom_hostname_callable
      AIRFLOW__CORE__LOAD_EXAMPLES: False
      AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG: 32
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql://$POSTGRES_USER:$POSTGRES_PASSWORD@${DATABASE_HOST}:${DATABASE_PORT}/postgres
      AIRFLOW__LOGGING__LOGGING_LEVEL: INFO
      AIRFLOW__LOGGING__WORKER_LOG_SERVER_PORT: 8793
      AIRFLOW__WEBSERVER__AUTHENTICATE: False
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: True
      AIRFLOW__WEBSERVER__RBAC: False
      AIRFLOW__WEBSERVER__SECRET_KEY: fullsvc
      DATABASE_CELERY_CMD: echo -n "db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${DATABASE_HOST}:${DATABASE_PORT}/postgres"
      DATABASE_HOST: postgres-service.airflow-schema.airflow-db.snowflakecomputing.internal
      DATABASE_PORT: 5432
      POSTGRES_USER: postgres
      REDIS_DBNUM: 0
      REDIS_HOST: redis-service.airflow-schema.airflow-db.snowflakecomputing.internal
      REDIS_PORT: 6379
      USE_HOSTNAME: No
      WORKER_NAME: airflow-worker.airflow-schema.airflow-db.snowflakecomputing.internal
      WORKER_TYPE: ip
    command:
    - bash
    - -c
    - "airflow users create -r Admin -u airflow -e airflow@test.com -f airflow -l airflow -p airflow && airflow sync-perm && airflow webserver"
    volumeMounts:
    - name: dags
      mountPath: /opt/airflow/dags
    - name: airflow-logs
      mountPath: /opt/airflow/logs
  - name: git-sync
    image: /airflow_db/airflow_schema/airflow_repository/gitsync:latest
    command:
        - bash
        - -c
        - "$HOME/git-sync.sh"
    volumeMounts:
      - name: dags
        mountPath: /dags
  endpoint:
  - name: runner
    port: 8001
  - name: webserver
    port: 8080
    public: true
  volumes:
  - name: dags
    source: "@airflow_db.airflow_schema.airflow_dags"
    uid: 50000
    gid: 50000
  - name: airflow-logs
    source: "@airflow_db.airflow_schema.airflow_logs"
    uid: 50000
    gid: 50000
